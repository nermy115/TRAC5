name: Job Scraper

on:
  schedule:
    - cron: "*/5 8-17 * * 1-5"  # Every 5 minutes from 8AM-5PM UTC, Mon-Fri
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          persist-credentials: false

      - name: Install Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run scraper
        env:
          EMAIL: ${{ secrets.EMAIL }}
          APP_PASSWORD: ${{ secrets.APP_PASSWORD }}
        run: python job_monitor.py || echo "Script failed but proceeding..."

      - name: Upload Debug Files
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: nhs-jobs-debug
          path: debug_page_*.html

      - name: Commit new job IDs
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          
          if [ -f "jobs.txt" ]; then
            git add jobs.txt
            git commit -m "Update tracked job IDs" || echo "No changes"
            git remote set-url origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}
            git push origin HEAD:${{ github.ref }}
          else
            echo "No jobs.txt to commit."
          fi
